# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from openai import AzureOpenAI
from openai.types.chat import (
    ChatCompletionUserMessageParam,
    ChatCompletionSystemMessageParam,
    ChatCompletionAssistantMessageParam,
    ChatCompletionMessageParam
)
from dotenv import load_dotenv
import streamlit as st
import os

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚ã®ã¿æœ‰åŠ¹ï¼‰
load_dotenv()

# Azure OpenAI æ¥ç¶šæƒ…å ±ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
client = AzureOpenAI(
    api_version="2025-01-01-preview",
    azure_endpoint=os.getenv("AZURE_API_ENDPOINT"),
    api_key=os.getenv("AZURE_API_KEY")
)

deployment_name = "gpt-4o-mini-assistant"

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # type: list[ChatCompletionMessageParam]

# å¿œç­”ç”Ÿæˆé–¢æ•°
def get_response(prompt: str) -> str:
    st.session_state.chat_history.append(
        ChatCompletionUserMessageParam(role="user", content=prompt)
    )

    system_message = ChatCompletionSystemMessageParam(
        role="system", content="You are a helpful assistant."
    )

    response_stream = client.chat.completions.create(
        model=deployment_name,
        messages=[system_message] + st.session_state.chat_history,
        stream=True
    )

    full_response = ""
    for chunk in response_stream:
        if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
            full_response += chunk.choices[0].delta.content

    return full_response

# å¿œç­”å±¥æ­´ã®è¿½åŠ é–¢æ•°
def add_history(response: str):
    st.session_state.chat_history.append(
        ChatCompletionAssistantMessageParam(role="assistant", content=response)
    )

# Streamlit UI
st.title("ğŸ’¬ ChatGPT-like cloneï¼ˆAzure OpenAI Ã— Streamlitï¼‰")

for chat in st.session_state.chat_history:
    with st.chat_message(chat.role):
        st.markdown(chat.content)

prompt = st.chat_input("ä½•ã‹è©±ã—ã‹ã‘ã¦ã¿ã¦ãã ã•ã„ï¼")
if prompt:
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response_text = get_response(prompt)
        st.markdown(response_text)

    add_history(response_text)
