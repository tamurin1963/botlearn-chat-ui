# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from openai import AzureOpenAI
from openai.types.chat import (
    ChatCompletionUserMessageParam,
    ChatCompletionSystemMessageParam,
    ChatCompletionAssistantMessageParam,
    ChatCompletionMessageParam,
    ChatCompletionChunk  # â† ä¿®æ­£æ¸ˆã¿
)
from dotenv import load_dotenv
import streamlit as st
import os
from typing import cast, List

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# Azure OpenAI æ¥ç¶šæƒ…å ±ï¼ˆ.envã«æº–æ‹ ï¼‰
client = AzureOpenAI(
    api_version=os.getenv("CHATBOT_AZURE_OPENAI_API_VERSION", ""),
    azure_endpoint=os.getenv("CHATBOT_AZURE_OPENAI_ENDPOINT", ""),
    api_key=os.getenv("CHATBOT_AZURE_OPENAI_API_KEY", "")
)

deployment_name = os.getenv("CHATBOT_AZURE_OPENAI_DEPLOYMENT_NAME", "")
assert deployment_name, "ç’°å¢ƒå¤‰æ•° CHATBOT_AZURE_OPENAI_DEPLOYMENT_NAME ãŒæœªè¨­å®šã§ã™"

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# å¿œç­”ç”Ÿæˆé–¢æ•°
def get_response(prompt: str) -> str:
    st.session_state.chat_history.append(
        ChatCompletionUserMessageParam(role="user", content=prompt)
    )

    system_message = ChatCompletionSystemMessageParam(
        role="system", content="You are a helpful assistant."
    )

    response_stream = client.chat.completions.create(
        model="Botlearn-gpt-4.0-mini",
        
        messages=[system_message] + st.session_state.chat_history,
        stream=True
    )

    full_response = ""

    for raw_chunk in response_stream:
        chunk = cast(ChatCompletionChunk, raw_chunk)
        if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
            full_response += chunk.choices[0].delta.content

    return full_response  # âœ… forãƒ«ãƒ¼ãƒ—ã®å¤–ãƒ»é–¢æ•°ã®ä¸­ã«ã‚ã‚‹

# å¿œç­”å±¥æ­´ã®è¿½åŠ é–¢æ•°
def add_history(response: str):
    st.session_state.chat_history.append(
        ChatCompletionAssistantMessageParam(role="assistant", content=response)
    )

# Streamlit UI
st.title("ğŸ’¬ ChatGPT-like cloneï¼ˆAzure OpenAI Ã— Streamlitï¼‰")

for chat in st.session_state.chat_history:
    with st.chat_message(chat.role):
        st.markdown(chat.content)

prompt = st.chat_input("ä½•ã‹è©±ã—ã‹ã‘ã¦ã¿ã¦ãã ã•ã„ï¼")
if prompt:
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response_text = get_response(prompt)
        st.markdown(response_text)

    add_history(response_text)
