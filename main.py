# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from openai import AzureOpenAI
from openai.types.chat import (
    ChatCompletionUserMessageParam,
    ChatCompletionSystemMessageParam,
    ChatCompletionAssistantMessageParam,
    ChatCompletionMessageParam
)
from dotenv import load_dotenv
import streamlit as st
import os
from typing import cast
from openai.types.chat import ChatCompletionCh
# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# Azure OpenAI æ¥ç¶šæƒ…å ±ï¼ˆ.envã«æº–æ‹ ï¼ï¼‰
client = AzureOpenAI(
    api_version=os.getenv("CHATBOT_AZURE_OPENAI_API_VERSION", ""),
    azure_endpoint=os.getenv("CHATBOT_AZURE_OPENAI_ENDPOINT", ""),
    api_key=os.getenv("CHATBOT_AZURE_OPENAI_API_KEY", "")
)

deployment_name = os.getenv("CHATBOT_AZURE_OPENAI_DEPLOYMENT_NAME")  # â† ä¸Šæ›¸ããªã—ï¼

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "chat_history" not in st.session_state:
    st.session_state.chat_history: List[ChatCompletionMessageParam] = []

# å¿œç­”ç”Ÿæˆé–¢æ•°
def get_response(prompt: str) -> str:
    st.session_state.chat_history.append(
        ChatCompletionUserMessageParam(role="user", content=prompt)
    )

    system_message = ChatCompletionSystemMessageParam(
        role="system", content="You are a helpful assistant."
    )

    response_stream = client.chat.completions.create(
    model=deployment_name,  # â† ã“ã“ã¯ str å‹ãŒä¿è¨¼ã•ã‚Œã¦ã„ã‚‹ã®ã§å®‰å¿ƒï¼
    messages=[system_message] + st.session_state.chat_history,
    stream=True
)


for raw_chunk in response_stream:
    chunk = cast(ChatCompletionChunk, raw_chunk)
    if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
        full_response += chunk.choices[0].delta.content
    return full_response

# å¿œç­”å±¥æ­´ã®è¿½åŠ é–¢æ•°
def add_history(response: str):
    st.session_state.chat_history.append(
        ChatCompletionAssistantMessageParam(role="assistant", content=response)
    )

# Streamlit UI
st.title("ğŸ’¬ ChatGPT-like cloneï¼ˆAzure OpenAI Ã— Streamlitï¼‰")

for chat in st.session_state.chat_history:
    with st.chat_message(chat.role):
        st.markdown(chat.content)

prompt = st.chat_input("ä½•ã‹è©±ã—ã‹ã‘ã¦ã¿ã¦ãã ã•ã„ï¼")
if prompt:
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response_text = get_response(prompt)
        st.markdown(response_text)

    add_history(response_text)
